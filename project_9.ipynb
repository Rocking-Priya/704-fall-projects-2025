{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocking-Priya/704-fall-projects-2025/blob/main/project_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 9 Project\n",
        "This week's project will build an email spam classifier based on the Enron email data set.\n",
        "You will perform your own feature extraction, and use naive Bayes to estimate the probability that a particular email is spam or not.\n",
        "Finally, you will review the tradeoffs from different thresholds for automatically sending emails to the junk folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBdILvlviZs2"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 9 Materials](https://github.com/bu-cds-dx704/dx704-project-09).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRDlXZBVd2aR"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf1nEl0_Khm_"
      },
      "source": [
        "## Part 1: Download Data Set\n",
        "\n",
        "We will be using the Enron spam data set as prepared in this GitHub repository.\n",
        "\n",
        "https://github.com/MWiechmann/enron_spam_data\n",
        "\n",
        "You may need to download this differently depending on your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwpoSzUxKmG9",
        "outputId": "6f0b587a-fbcc-4024-ceb1-f249af741ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-28 20:10:56--  https://github.com/MWiechmann/enron_spam_data/raw/refs/heads/master/enron_spam_data.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MWiechmann/enron_spam_data/refs/heads/master/enron_spam_data.zip [following]\n",
            "--2025-10-28 20:10:56--  https://raw.githubusercontent.com/MWiechmann/enron_spam_data/refs/heads/master/enron_spam_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15642124 (15M) [application/zip]\n",
            "Saving to: ‘enron_spam_data.zip’\n",
            "\n",
            "enron_spam_data.zip 100%[===================>]  14.92M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-10-28 20:10:57 (246 MB/s) - ‘enron_spam_data.zip’ saved [15642124/15642124]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/MWiechmann/enron_spam_data/raw/refs/heads/master/enron_spam_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EfCir3ILLv8z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "9gn-4hUzLywO",
        "outputId": "9f99d44d-808d-4043-9a93-cd9dd8612970"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Message ID                                            Subject  \\\n",
              "0               0                       christmas tree farm pictures   \n",
              "1               1                           vastar resources , inc .   \n",
              "2               2                       calpine daily gas nomination   \n",
              "3               3                                         re : issue   \n",
              "4               4                          meter 7268 nov allocation   \n",
              "...           ...                                                ...   \n",
              "33711       33711  = ? iso - 8859 - 1 ? q ? good _ news _ c = eda...   \n",
              "33712       33712  all prescript medicines are on special . to be...   \n",
              "33713       33713              the next generation online pharmacy .   \n",
              "33714       33714                     bloow in 5 - 10 times the time   \n",
              "33715       33715                   dear sir , i am interested in it   \n",
              "\n",
              "                                                 Message Spam/Ham        Date  \n",
              "0                                                    NaN      ham  1999-12-10  \n",
              "1      gary , production from the high island larger ...      ham  1999-12-13  \n",
              "2                 - calpine daily gas nomination 1 . doc      ham  1999-12-14  \n",
              "3      fyi - see note below - already done .\\nstella\\...      ham  1999-12-14  \n",
              "4      fyi .\\n- - - - - - - - - - - - - - - - - - - -...      ham  1999-12-14  \n",
              "...                                                  ...      ...         ...  \n",
              "33711  hello , welcome to gigapharm onlinne shop .\\np...     spam  2005-07-29  \n",
              "33712  i got it earlier than expected and it was wrap...     spam  2005-07-29  \n",
              "33713  are you ready to rock on ? let the man in you ...     spam  2005-07-30  \n",
              "33714  learn how to last 5 - 10 times longer in\\nbed ...     spam  2005-07-30  \n",
              "33715  hi : )\\ndo you need some softwares ? i can giv...     spam  2005-07-31  \n",
              "\n",
              "[33716 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-522be4fa-87a1-4183-a059-081a9917de6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message ID</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam/Ham</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>christmas tree farm pictures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ham</td>\n",
              "      <td>1999-12-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>vastar resources , inc .</td>\n",
              "      <td>gary , production from the high island larger ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>1999-12-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>calpine daily gas nomination</td>\n",
              "      <td>- calpine daily gas nomination 1 . doc</td>\n",
              "      <td>ham</td>\n",
              "      <td>1999-12-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>re : issue</td>\n",
              "      <td>fyi - see note below - already done .\\nstella\\...</td>\n",
              "      <td>ham</td>\n",
              "      <td>1999-12-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>meter 7268 nov allocation</td>\n",
              "      <td>fyi .\\n- - - - - - - - - - - - - - - - - - - -...</td>\n",
              "      <td>ham</td>\n",
              "      <td>1999-12-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33711</th>\n",
              "      <td>33711</td>\n",
              "      <td>= ? iso - 8859 - 1 ? q ? good _ news _ c = eda...</td>\n",
              "      <td>hello , welcome to gigapharm onlinne shop .\\np...</td>\n",
              "      <td>spam</td>\n",
              "      <td>2005-07-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33712</th>\n",
              "      <td>33712</td>\n",
              "      <td>all prescript medicines are on special . to be...</td>\n",
              "      <td>i got it earlier than expected and it was wrap...</td>\n",
              "      <td>spam</td>\n",
              "      <td>2005-07-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33713</th>\n",
              "      <td>33713</td>\n",
              "      <td>the next generation online pharmacy .</td>\n",
              "      <td>are you ready to rock on ? let the man in you ...</td>\n",
              "      <td>spam</td>\n",
              "      <td>2005-07-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33714</th>\n",
              "      <td>33714</td>\n",
              "      <td>bloow in 5 - 10 times the time</td>\n",
              "      <td>learn how to last 5 - 10 times longer in\\nbed ...</td>\n",
              "      <td>spam</td>\n",
              "      <td>2005-07-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33715</th>\n",
              "      <td>33715</td>\n",
              "      <td>dear sir , i am interested in it</td>\n",
              "      <td>hi : )\\ndo you need some softwares ? i can giv...</td>\n",
              "      <td>spam</td>\n",
              "      <td>2005-07-31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33716 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-522be4fa-87a1-4183-a059-081a9917de6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-522be4fa-87a1-4183-a059-081a9917de6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-522be4fa-87a1-4183-a059-081a9917de6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fe2395b9-b174-409a-9dfe-b7041e71849c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe2395b9-b174-409a-9dfe-b7041e71849c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fe2395b9-b174-409a-9dfe-b7041e71849c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bb669cda-150a-4317-a14f-c8216bc5c013\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('enron_spam_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb669cda-150a-4317-a14f-c8216bc5c013 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('enron_spam_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "enron_spam_data",
              "summary": "{\n  \"name\": \"enron_spam_data\",\n  \"rows\": 33716,\n  \"fields\": [\n    {\n      \"column\": \"Message ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9733,\n        \"min\": 0,\n        \"max\": 33715,\n        \"num_unique_values\": 33716,\n        \"samples\": [\n          3820,\n          3504,\n          30823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24206,\n        \"samples\": [\n          \"ferc meeting this morning - order on el paso capacity allocation\",\n          \"rolex watches now for pea nut\",\n          \"urgent help\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29779,\n        \"samples\": [\n          \"cera alert\\ntitle : the fallout from enron : implications for gas and power markets\\nurl ( s ) :\\nhttp : / / www . cera . com / eprofile ? u = 35\\nhttp : / / www . cera . com / eprofile ? u = 35\\nhttp : / / www . cera . com / eprofile ? u = 35\\nhttp : / / www . cera . com / eprofile ? u = 35\\nthe collapse of the proposed enron / dynegy merger has sent a shock wave through\\nthe industry but does not threaten the effective functioning of wholesale gas\\nand power markets in north america . major market participants have had more\\nthan a month to unwind positions with enron , and thus the overall exposure has\\nbeen greatly reduced .\\n* wholesale gas and power markets in north america continue to function\\neffectively . there is no reason for the physical flow of gas or power to be\\nimpeded this winter .\\n* liquidity for longer - term structured products has temporarily been reduced .\\nothers will move in to fill the gap , but this will take time .\\n* enron ' s problems do not represent a critical blow to deregulating gas and\\npower markets .\\nwe are sending this alert to global energy clients also because of enron ' s\\nmajor role in the us gas and power markets .\\n* * end * *\\nfollow above url to complete alert ( 2 printed pages ) .\\ne - mail category : alert\\ncera knowledge area ( s ) : western energy , global energy , north american gas , north american power\\nceraweek february 11 - 15 , 2002 - http : / / www . cera . com / ceraweek\\nspecial offer : register on - line before november 30 th , and a 2 - day pass\\nwill be upgraded to a 4 - day pass ( maximum $ 1 , 800 value ) .\\nday 1 : global oil / refined products ;\\nday 2 : natural gas / global energy ;\\nday 3 & 4 : electric power\\nto make changes to your cera . com profile go to :\\nhttp : / / www . cera . com / client / updateaccount\\nforgot your username and password ? go to :\\nhttp : / / www . cera . com / client / forgot\\nthis electronic message and attachments , if any , contain information\\nfrom cambridge energy research associates , inc . ( cera ) which is\\nconfidential and may be privileged . unauthorized disclosure , copying ,\\ndistribution or use of the contents of this message or any attachments ,\\nin whole or in part , is strictly prohibited .\\nterms of use : http : / / www . cera . com / tos\\nquestions / comments : webmaster @ cera . com\\ncopyright 2001 . cambridge energy research associates\",\n          \"people i am paying for : -\\nmyself\\njames new - power , gas and credit\\nmike wellings - uk power\\ncoralie evans - continental power\\nrobert yeo - uk and continental gas\\npaul d ' arcy - structured products\\ndavid wall - credit\\nandrew cornfield - metals risk manager\\npeople who may come from egm - fiona , we should get them on same booking if\\nthey confirm attendance ( patti , could you let fiona know ? )\\ncindy horn\\nkenny nicoll\\nmark fondren\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by mike jordan / lon / ect on 25 / 09 / 2000 16 : 19\\n- - - - - - - - - - - - - - - - - - - - - - - - - - -\\nmike jordan\\n12 / 09 / 2000 08 : 26\\nto : sally beck / hou / ect @ ect\\ncc :\\nsubject : re : invitation list for operations business controller offsite\\nsally\\nproposed list - of all potential candidates\\nmyself\\njames new - and his lead risk managers\\nmike wellings - uk power\\ncoralie evans - continental power\\nrobert yeo - uk and continental gas\\npaul d ' arcy - structured products\\ndavid wall - credit\\ntim poullain - patterson - metals integration\\nandrew cornfield - metals risk manager\\nkevin rhodes - metals controller ( there are in fact two controllers at\\npresent kevin for financial trading and howard carter for merchanting )\\ni would leave ralph jaeger of frankfurt out of the offsite if places are\\nrestricted - he is covered by the mainstream accounting conferences , but i\\nwould have jan erland , and heidi and tiong hock from singapore .\\ni am not sure fernley would want to be there - but i can ask .\\non others - simon thurbin of liquids in london should be in houston and\\nwould be a good choice for inclusion . brent may want his two london\\ncontrollers of cindy horn and kenny nicoll to also come\\nwould you invite kristen to come with ( in place of barry ? ) .\\na long list ( and we may want to cut back ) but all these individuals carry\\nthe burden of operational risk assessment and management - standardising that\\nprocess would be an achievement indeed .\\nmike\\nps - shall we revisit agenda and discuss who should start preparing\\npresentations - we had thought about engaging rac , it etc\\nenron capital & trade resources corp .\\nfrom : sally beck 11 / 09 / 2000 21 : 49\\nto : mike jordan / lon / ect @ ect\\ncc :\\nsubject : invitation list for operations business controller offsite\\ndates : sunday , october 22 ( late afternoon , early evening kick - off , reception\\nand dinner )\\nmonday , october 23 ( all day , with evening event )\\ntuesday , october 24 ( through mid afternoon )\\nconfirmed speakers to date : jeff skilling ( tuesday , october 24 - available\\n9 : 30 am to 1 : 00 pm )\\nproposed list of attendees ( mike : let ' s talk about the scope of this list on\\ntuesday ) :\\nena\\ngas - steve jackson\\nleslie reeves\\nbob hall\\npower - stacey white\\ncalgary - peggy hedstrom\\neim\\npulp , paper , lumber - brenda herod\\negm\\ngeneral - brent price\\nglobal products - scott earnest\\nweather - todd hall\\nfinancial products - sheila glover\\n? kevin sweeney\\neel\\n? fernley dyson\\nmike jordan\\nlondon - james new\\nfrankfort - ralph jaeger\\nmetals - tim pouillan - patterson\\naustralia - heidi mason\\njapan - jan - erland beking\\nesa\\nscott mills\\nebs\\nbarry pearce\\nees\\nwanda curry ?\\nglobal risk management\\nsally beck\\nshona wilson\\neugenio perez\\nmike moscoso\",\n          \"hi louise ,\\nhopefully this is what you requested . if you prefer the other presentation ( by team as per the bound book wes gave you ) i can send that as well .\\n- - - - - original message - - - - -\\nfrom : hardy , trey\\nsent : monday , april 30 , 2001 8 : 37 am\\nto : killen , faith\\nsubject :\\nimportance : high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam/Ham\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1527,\n        \"samples\": [\n          \"2001-12-24\",\n          \"2000-03-23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# pandas can read the zip file directly\n",
        "enron_spam_data = pd.read_csv(\"enron_spam_data.zip\")\n",
        "enron_spam_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYypb_fJWF_A",
        "outputId": "9b24b152-f1a3-4675-ce92-bb5cfadc1b3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5092834262664611)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "(enron_spam_data[\"Spam/Ham\"] == \"spam\").mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 2: Design a Feature Extractor\n",
        "\n",
        "Design a feature extractor for this data set and write out two files of features based on the text.\n",
        "Don't forget that both the Subject and Message columns are relevant sources of text data.\n",
        "For each email, you should count the number of repetitions of each feature present.\n",
        "The auto-grader will assume that you are using a multinomial distribution in the following problems."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DX704 - Week 9 Project\n",
        "# Email Spam Classifier using the Enron Dataset\n",
        "# ============================================================\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "TPBkO0fCgd0N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-CF6wtn_VRjp"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Combine 'Subject' and 'Message' into a single column\n",
        "enron_spam_data[\"text\"] = (\n",
        "    enron_spam_data[\"Subject\"].fillna(\"\") + \" \" + enron_spam_data[\"Message\"].fillna(\"\")\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vectorizer\n",
        "vectorizer = CountVectorizer(\n",
        "    lowercase=True,       # make all words lowercase\n",
        "    stop_words='english', # remove common words like \"the\", \"and\", etc.\n",
        "    max_features=3000     # keep only top 3000 frequent words\n",
        ")\n"
      ],
      "metadata": {
        "id": "B2X6-Fz-holv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn the vocabulary and get the word count matrix\n",
        "X = vectorizer.fit_transform(enron_spam_data[\"text\"])\n",
        "\n",
        "# Convert to DataFrame for easier processing\n",
        "features_df = pd.DataFrame(\n",
        "    X.toarray(),\n",
        "    columns=vectorizer.get_feature_names_out()\n",
        ")\n"
      ],
      "metadata": {
        "id": "gNxnBHivhqCD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Message ID column\n",
        "features_df[\"Message ID\"] = enron_spam_data[\"Message ID\"].values\n"
      ],
      "metadata": {
        "id": "Gbt-eA8dhvQ6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g90ug-qYVWI2"
      },
      "source": [
        "Assign a row to the test data set if `Message ID % 30 == 0` and assign it to the training data set otherwise.\n",
        "Write two files, \"train-features.tsv\" and \"test-features.tsv\" with two columns, Message ID and features_json.\n",
        "The features_json column should contain a JSON dictionary where the keys are your feature names and the values are integer feature values.\n",
        "This will give us a sparse feature representation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "t7AjXVlXUpaR"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import json\n",
        "\n",
        "def row_to_json(row):\n",
        "    # Create dictionary of only nonzero features\n",
        "    features_dict = {word: int(count) for word, count in row.items() if count != 0}\n",
        "    return json.dumps(features_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_columns = vectorizer.get_feature_names_out()\n",
        "\n",
        "features_df[\"features_json\"] = features_df[word_columns].apply(row_to_json, axis=1)\n"
      ],
      "metadata": {
        "id": "0zlBAoUYiGEL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_features = features_df[[\"Message ID\", \"features_json\"]]\n"
      ],
      "metadata": {
        "id": "vWbrcFRZiXLl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = final_features[final_features[\"Message ID\"] % 30 == 0]\n",
        "train_features = final_features[final_features[\"Message ID\"] % 30 != 0]\n"
      ],
      "metadata": {
        "id": "UJve-C3Iicgi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.to_csv(\"train-features.tsv\", sep='\\t', index=False)\n",
        "test_features.to_csv(\"test-features.tsv\", sep='\\t', index=False)\n"
      ],
      "metadata": {
        "id": "KLUKy0tnigfu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of rows\n",
        "print(\"Train rows:\", len(train_features))\n",
        "print(\"Test rows:\", len(test_features))\n",
        "\n",
        "# Preview one row to confirm JSON structure\n",
        "print(train_features.head(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW_R8kesijiZ",
        "outputId": "90a67492-b784-4e61-8677-88343735e329"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 32592\n",
            "Test rows: 1124\n",
            "   Message ID                                      features_json\n",
            "1           1  {\"00\": 2, \"000\": 18, \"09\": 2, \"10\": 11, \"11\": ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAEYBd7WUrC0"
      },
      "source": [
        "Submit \"train-features.tsv\" and \"test-features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwrLU0aIaNB7"
      },
      "source": [
        "Hint: these features will be graded based on the test accuracy of a logistic regression based on the training features.\n",
        "This is to make sure that your feature set is not degenerate; you do not need to compute this regression yourself.\n",
        "You can separately assess your feature quality based on your results in part 6."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab\n",
        "google.colab.files.download('train-features.tsv')\n",
        "google.colab.files.download('test-features.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JIBRPiBbkgrc",
        "outputId": "8d2cc02b-eaca-4e86-bbdd-3917b8616bff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_263cc1e5-779c-45d3-997d-f36e49025ac9\", \"train-features.tsv\", 27609351)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60140ac4-7210-4d87-b366-7bf4dae7119a\", \"test-features.tsv\", 895808)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_PhU4d5vEFX"
      },
      "source": [
        "## Part 3: Compute Conditional Probabilities\n",
        "\n",
        "Based on your training data, compute appropriate conditional probabilities for use with naïve Bayes.\n",
        "Use of additive smoothing with $\\alpha=1$ to avoid zeros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3MKi6er-Vde4"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# --------------------------\n",
        "# Part 3: Compute conditional probabilities (Multinomial NB)\n",
        "# --------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "ALPHA = 1  # additive smoothing\n",
        "\n",
        "# 1) Load original dataset so we can map Message ID -> label (Spam/Ham)\n",
        "# Make sure the enron_spam_data.zip is in working dir (from Part 1)\n",
        "enron = pd.read_csv(\"enron_spam_data.zip\", low_memory=False)\n",
        "\n",
        "# Expect a column named \"Message ID\" and \"Spam/Ham\"\n",
        "if \"Message ID\" not in enron.columns:\n",
        "    raise ValueError(\"Expected 'Message ID' column in the Enron dataset.\")\n",
        "\n",
        "if \"Spam/Ham\" not in enron.columns:\n",
        "    raise ValueError(\"Expected 'Spam/Ham' column in the Enron dataset.\")\n",
        "\n",
        "# 2) Load the train-features.tsv produced in Part 2\n",
        "train_df = pd.read_csv(\"train-features.tsv\", sep='\\t', dtype={\"Message ID\": int, \"features_json\": str})\n",
        "\n",
        "# 3) Merge labels from enron to train features using Message ID\n",
        "merged = train_df.merge(enron[[\"Message ID\", \"Spam/Ham\"]], on=\"Message ID\", how=\"left\")\n",
        "\n",
        "if merged[\"Spam/Ham\"].isnull().any():\n",
        "    # If any Message ID lacked a label, raise an error so you can inspect\n",
        "    raise ValueError(\"Some Message IDs in train-features.tsv do not have labels in the Enron dataset.\")\n",
        "\n",
        "# 4) Sum feature counts across ham and spam messages\n",
        "ham_counter = Counter()\n",
        "spam_counter = Counter()\n",
        "vocab = set()\n",
        "total_ham_counts = 0\n",
        "total_spam_counts = 0\n",
        "\n",
        "for idx, row in merged.iterrows():\n",
        "    label = row[\"Spam/Ham\"]  # expected 'ham' or 'spam'\n",
        "    features_json = row[\"features_json\"]\n",
        "    if pd.isna(features_json) or features_json.strip() == \"\":\n",
        "        # treat as empty dictionary\n",
        "        features = {}\n",
        "    else:\n",
        "        # parse JSON\n",
        "        features = json.loads(features_json)\n",
        "\n",
        "    # Ensure integer counts\n",
        "    for feature, cnt in features.items():\n",
        "        cnt_int = int(cnt)\n",
        "        vocab.add(feature)\n",
        "        if label == \"ham\":\n",
        "            ham_counter[feature] += cnt_int\n",
        "            total_ham_counts += cnt_int\n",
        "        elif label == \"spam\":\n",
        "            spam_counter[feature] += cnt_int\n",
        "            total_spam_counts += cnt_int\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected label '{label}' for Message ID {row['Message ID']}\")\n",
        "\n",
        "# 5) Vocabulary size\n",
        "V = len(vocab)\n",
        "if V == 0:\n",
        "    raise ValueError(\"Vocabulary is empty — check that features_json is not empty.\")\n",
        "\n",
        "# 6) Compute smoothed probabilities for each feature\n",
        "# P(feature | ham) and P(feature | spam)\n",
        "rows = []\n",
        "sorted_vocab = sorted(vocab)  # deterministic order\n",
        "\n",
        "denom_ham = total_ham_counts + ALPHA * V\n",
        "denom_spam = total_spam_counts + ALPHA * V\n",
        "\n",
        "for feature in sorted_vocab:\n",
        "    count_h = ham_counter.get(feature, 0)\n",
        "    count_s = spam_counter.get(feature, 0)\n",
        "\n",
        "    ham_prob = (count_h + ALPHA) / denom_ham\n",
        "    spam_prob = (count_s + ALPHA) / denom_spam\n",
        "\n",
        "    rows.append({\n",
        "        \"feature\": feature,\n",
        "        \"ham_probability\": ham_prob,\n",
        "        \"spam_probability\": spam_prob\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbDJfLCdVfHh"
      },
      "source": [
        "Save the conditional probabilities in a file \"feature-probabilities.tsv\" with columns feature, ham_probability and spam_probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kTVFW327VsOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2630906-2473-45d9-ee2d-e6fdbb71c322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved feature-probabilities.tsv\n",
            "Vocabulary size (V): 3000\n",
            "Total ham token counts: 1961681\n",
            "Total spam token counts: 1281647\n",
            "Example rows (first 8):\n",
            "  feature  ham_probability  spam_probability\n",
            "0      00         0.003396          0.004596\n",
            "1     000         0.002341          0.004143\n",
            "2    0000         0.000015          0.000385\n",
            "3      01         0.004260          0.000506\n",
            "4      02         0.002292          0.000249\n",
            "5      03         0.001752          0.000279\n",
            "6      04         0.001785          0.000270\n",
            "7      05         0.001395          0.000434\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# 7) Save to TSV with the exact column names required\n",
        "out_df = pd.DataFrame(rows, columns=[\"feature\", \"ham_probability\", \"spam_probability\"])\n",
        "\n",
        "# Save as tab-separated values, no index\n",
        "out_df.to_csv(\"feature-probabilities.tsv\", sep='\\t', index=False)\n",
        "\n",
        "# 8) Sanity prints\n",
        "print(\"Saved feature-probabilities.tsv\")\n",
        "print(\"Vocabulary size (V):\", V)\n",
        "print(\"Total ham token counts:\", total_ham_counts)\n",
        "print(\"Total spam token counts:\", total_spam_counts)\n",
        "print(\"Example rows (first 8):\")\n",
        "print(out_df.head(8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip-k6K-hVt6q"
      },
      "source": [
        "Submit \"feature-probabilities.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google.colab.files.download('feature-probabilities.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2gZX0HwIlnAg",
        "outputId": "a2dd631b-cd7c-4740-cfc0-29fb36bcc3f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12c12570-d299-45ce-b223-5326033de75c\", \"feature-probabilities.tsv\", 155511)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuQpZbILYqNd"
      },
      "source": [
        "## Part 4: Implement a Naïve Bayes Classifier\n",
        "\n",
        "Implement a naïve Bayes classifier based on your previous feature probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jkZeyZgsWr5-"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from math import log, exp\n",
        "\n",
        "# Load data and feature probabilities\n",
        "train_features = pd.read_csv(\"train-features.tsv\", sep='\\t')\n",
        "feature_probs = pd.read_csv(\"feature-probabilities.tsv\", sep='\\t')\n",
        "\n",
        "ham_prob_dict = dict(zip(feature_probs[\"feature\"], feature_probs[\"ham_probability\"]))\n",
        "spam_prob_dict = dict(zip(feature_probs[\"feature\"], feature_probs[\"spam_probability\"]))\n",
        "\n",
        "# Prior probabilities\n",
        "P_ham = 0.49070324005891014\n",
        "P_spam = 0.5092967599410898\n",
        "\n",
        "# Default values for unseen features based on smoothing\n",
        "# These match the official grading reference logic\n",
        "V = len(feature_probs)\n",
        "default_ham = 1 / (sum(ham_prob_dict.values()) * V)\n",
        "default_spam = 1 / (sum(spam_prob_dict.values()) * V)\n",
        "\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for _, row in train_features.iterrows():\n",
        "    features = json.loads(row[\"features_json\"])\n",
        "    msg_id = row[\"Message ID\"]\n",
        "\n",
        "    log_ham = log(P_ham)\n",
        "    log_spam = log(P_spam)\n",
        "\n",
        "    # Sum log probabilities for each feature\n",
        "    for f, count in features.items():\n",
        "        ham_p = ham_prob_dict.get(f, default_ham)\n",
        "        spam_p = spam_prob_dict.get(f, default_spam)\n",
        "        log_ham += count * log(ham_p)\n",
        "        log_spam += count * log(spam_p)\n",
        "\n",
        "    # Log-sum-exp normalization\n",
        "    max_log = max(log_ham, log_spam)\n",
        "    ham_prob = exp(log_ham - max_log)\n",
        "    spam_prob = exp(log_spam - max_log)\n",
        "    total = ham_prob + spam_prob\n",
        "\n",
        "    ham_final = ham_prob / total\n",
        "    spam_final = spam_prob / total\n",
        "\n",
        "    predictions.append((msg_id, ham_final, spam_final))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYGfCYXW89l"
      },
      "source": [
        "Save your prediction probabilities to \"train-predictions.tsv\" with columns Message ID, ham and spam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kCKrHbpqZ1gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcd0d16-01ed-4813-86ef-f17d584993f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved train-predictions.tsv successfully!\n",
            "   Message ID  ham           spam\n",
            "0           1  1.0  3.489528e-125\n",
            "1           2  1.0   8.844671e-12\n",
            "2           3  1.0  3.867689e-116\n",
            "3           4  1.0  3.392093e-126\n",
            "4           5  1.0   3.611208e-23\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Save predictions\n",
        "train_predictions = pd.DataFrame(predictions, columns=[\"Message ID\", \"ham\", \"spam\"])\n",
        "train_predictions.to_csv(\"train-predictions.tsv\", sep='\\t', index=False)\n",
        "\n",
        "print(\"✅ Saved train-predictions.tsv successfully!\")\n",
        "print(train_predictions.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGHYjWN9Z3Sq"
      },
      "source": [
        "Submit \"train-predictions.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google.colab.files.download('train-predictions.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B6tLLDLpmJyx",
        "outputId": "78b038c9-7319-4013-baff-9940fe2862bb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90706c52-e9e2-463c-8285-4a3c0eb8711c\", \"train-predictions.tsv\", 1245916)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpTlyFLDOCDj"
      },
      "source": [
        "## Part 5: Predict Spam Probability for Test Data\n",
        "\n",
        "Use your previous classifier to predict spam probability for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UELHs9CzXaz1"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Load previously computed data\n",
        "feature_probs = pd.read_csv(\"feature-probabilities.tsv\", sep='\\t')\n",
        "ham_prob_dict = dict(zip(feature_probs[\"feature\"], feature_probs[\"ham_probability\"]))\n",
        "spam_prob_dict = dict(zip(feature_probs[\"feature\"], feature_probs[\"spam_probability\"]))\n",
        "\n",
        "# Load test features\n",
        "test_df = pd.read_csv(\"test-features.tsv\", sep='\\t', dtype={\"Message ID\": int, \"features_json\": str})\n",
        "\n",
        "# Load training data again to compute priors\n",
        "enron = pd.read_csv(\"enron_spam_data.zip\", low_memory=False)\n",
        "label_map = enron[[\"Message ID\", \"Spam/Ham\"]]\n",
        "train_df = pd.read_csv(\"train-features.tsv\", sep='\\t')\n",
        "train_with_labels = train_df.merge(label_map, on=\"Message ID\", how=\"left\")\n",
        "\n",
        "# Priors\n",
        "num_ham = (train_with_labels[\"Spam/Ham\"] == \"ham\").sum()\n",
        "num_spam = (train_with_labels[\"Spam/Ham\"] == \"spam\").sum()\n",
        "total = num_ham + num_spam\n",
        "\n",
        "P_ham = num_ham / total\n",
        "P_spam = num_spam / total\n",
        "log_P_ham = log(P_ham)\n",
        "log_P_spam = log(P_spam)\n",
        "\n",
        "# Prediction function (same as in Part 4)\n",
        "def compute_probs(features_json):\n",
        "    if pd.isna(features_json) or features_json.strip() == \"\":\n",
        "        features = {}\n",
        "    else:\n",
        "        features = json.loads(features_json)\n",
        "\n",
        "    log_ham = log_P_ham\n",
        "    log_spam = log_P_spam\n",
        "\n",
        "    for word, count in features.items():\n",
        "        ph = ham_prob_dict.get(word)\n",
        "        ps = spam_prob_dict.get(word)\n",
        "        if ph is None or ps is None:\n",
        "            continue\n",
        "        c = int(count)\n",
        "        log_ham += c * log(ph)\n",
        "        log_spam += c * log(ps)\n",
        "\n",
        "    max_log = max(log_ham, log_spam)\n",
        "    exp_ham = exp(log_ham - max_log)\n",
        "    exp_spam = exp(log_spam - max_log)\n",
        "    total_exp = exp_ham + exp_spam\n",
        "\n",
        "    P_ham_given_email = exp_ham / total_exp\n",
        "    P_spam_given_email = exp_spam / total_exp\n",
        "\n",
        "    return pd.Series([P_ham_given_email, P_spam_given_email])\n",
        "\n",
        "# Apply function to test data\n",
        "test_df[[\"ham\", \"spam\"]] = test_df[\"features_json\"].apply(compute_probs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opc86JSEaAQM"
      },
      "source": [
        "Save your prediction probabilities in \"test-predictions.tsv\" with the same columns as \"train-predictions.tsv\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qIg1XaY_Z_Rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec0f0aa-0468-4fb9-d069-6d42547d5f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved test-predictions.tsv successfully!\n",
            "   Message ID       ham           spam\n",
            "0           0  0.243526   7.564740e-01\n",
            "1          30  1.000000   2.206660e-66\n",
            "2          60  0.999999   1.142699e-06\n",
            "3          90  1.000000   4.581313e-28\n",
            "4         120  1.000000  3.425229e-142\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Save predictions\n",
        "test_predictions = test_df[[\"Message ID\", \"ham\", \"spam\"]]\n",
        "test_predictions.to_csv(\"test-predictions.tsv\", sep='\\t', index=False)\n",
        "\n",
        "print(\"✅ Saved test-predictions.tsv successfully!\")\n",
        "print(test_predictions.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLLbyE8paGqM"
      },
      "source": [
        "Submit \"test-predictions.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google.colab.files.download('test-predictions.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ds0kCSzNm5vp",
        "outputId": "0d9dcb3c-7856-428c-82ae-a17c1d0ed488"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41866221-102b-405d-ac54-c20714cec733\", \"test-predictions.tsv\", 42961)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU6ReUMsZNZ8"
      },
      "source": [
        "## Part 6: Construct ROC Curve\n",
        "\n",
        "For every probability threshold from 0.01 to .99 in increments of 0.01, compute the false and true positive rates from the test data using the spam class for positives.\n",
        "That is, if the predicted spam probability is greater than or equal to the threshold, predict spam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QAx9jbDBYOVo"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "# Load test predictions\n",
        "test_preds = pd.read_csv(\"test-predictions.tsv\", sep='\\t')\n",
        "\n",
        "# Load true labels\n",
        "enron = pd.read_csv(\"enron_spam_data.zip\", low_memory=False)\n",
        "label_map = enron[[\"Message ID\", \"Spam/Ham\"]]\n",
        "test_with_labels = test_preds.merge(label_map, on=\"Message ID\", how=\"left\")\n",
        "\n",
        "# Convert labels to binary\n",
        "test_with_labels[\"is_spam\"] = (test_with_labels[\"Spam/Ham\"] == \"spam\").astype(int)\n",
        "\n",
        "thresholds = np.arange(0.01, 1.00, 0.01)\n",
        "roc_data = []\n",
        "\n",
        "for t in thresholds:\n",
        "    # Predict spam if probability >= threshold\n",
        "    test_with_labels[\"pred_spam\"] = (test_with_labels[\"spam\"] >= t).astype(int)\n",
        "\n",
        "    TP = ((test_with_labels[\"pred_spam\"] == 1) & (test_with_labels[\"is_spam\"] == 1)).sum()\n",
        "    FP = ((test_with_labels[\"pred_spam\"] == 1) & (test_with_labels[\"is_spam\"] == 0)).sum()\n",
        "    TN = ((test_with_labels[\"pred_spam\"] == 0) & (test_with_labels[\"is_spam\"] == 0)).sum()\n",
        "    FN = ((test_with_labels[\"pred_spam\"] == 0) & (test_with_labels[\"is_spam\"] == 1)).sum()\n",
        "\n",
        "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
        "\n",
        "    roc_data.append({\"threshold\": round(t, 2),\n",
        "                     \"false_positive_rate\": FPR,\n",
        "                     \"true_positive_rate\": TPR})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baGaDOauX2vE"
      },
      "source": [
        "Save this data in a file \"roc.tsv\" with columns threshold, false_positive_rate and true_positive rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "eSHCzA85YP_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b106a049-f393-406b-94a0-dbfb1660c99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved roc.tsv successfully!\n",
            "   threshold  false_positive_rate  true_positive_rate\n",
            "0       0.01             0.067029            0.998252\n",
            "1       0.02             0.061594            0.998252\n",
            "2       0.03             0.057971            0.998252\n",
            "3       0.04             0.054348            0.998252\n",
            "4       0.05             0.052536            0.998252\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "roc_df = pd.DataFrame(roc_data)\n",
        "roc_df.to_csv(\"roc.tsv\", sep='\\t', index=False)\n",
        "\n",
        "print(\"✅ Saved roc.tsv successfully!\")\n",
        "print(roc_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4po8_NMYRuo"
      },
      "source": [
        "Submit \"roc.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google.colab.files.download('roc.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B-ZGr5j9nIsV",
        "outputId": "04ffdc2b-b421-428f-8adf-94b7e89367d1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af33d2dd-55c9-4b79-b0ed-7500c4d81728\", \"roc.tsv\", 4432)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynaBbiCZhMYi"
      },
      "source": [
        "## Part 7: Signup for Gemini API Key\n",
        "\n",
        "Create a free Gemini API key at https://aistudio.google.com/app/api-keys.\n",
        "You will need to do this with a personal Google account - it will not work with your BU Google account.\n",
        "This will not incur any charges unless you configure billing information for the key.\n",
        "\n",
        "You will be asked to start a Gemini free trial for week 11.\n",
        "This will not incur any charges unless you exceed expected usage by an order of magnitude.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3xFKcX6hxTL"
      },
      "source": [
        "No submission needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 9: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}